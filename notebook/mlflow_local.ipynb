{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1d19c5-8baa-4fe3-b38d-43c32a64573b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9add539b-d89c-4ebb-9719-276f94631d2a",
   "metadata": {},
   "source": [
    "# MLflow in Local\n",
    "\n",
    "For this demo, we'll implement MLflow scenario where we will use a SQLite database as the backend store and `mlruns` directory as the artifact store.\n",
    "\n",
    "The objective is we want to predict the trip duration based on the trip distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ed481-6fb1-43cd-af7e-d047d188ad84",
   "metadata": {},
   "source": [
    "## Configure MLflow Tracking URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c574c115-3380-44a3-8cb4-cbc6dd54af3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"duration-prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8097f3-7280-44db-82ad-9b3521a627b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40045bce-048f-48df-b798-31bb521b06af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlflow.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec92ccd-b825-4db8-a4d9-6c2098607800",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621068ba-29c3-4705-a9c8-dd33cedf13ff",
   "metadata": {},
   "source": [
    "After we set the experiment name, there'll be `mlruns` directory and a SQLite database `mlflow.db` generated automatically. We can access the database using `sqlite3` if we want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4953829e-b28a-4776-ae56-3d3d2bacf3bd",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa83b145-bdca-4fd9-9f0f-df744c3c8b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data\")\n",
    "DATA_RAW_DIR = DATA_DIR / \"raw\"\n",
    "GREEN_TRIP_JAN = DATA_RAW_DIR / \"green_tripdata_2022-01.csv\"\n",
    "GREEN_TRIP_FEB = DATA_RAW_DIR / \"green_tripdata_2022-02.csv\"\n",
    "GREEN_TRIP_MAR = DATA_RAW_DIR / \"green_tripdata_2022-03.csv\"\n",
    "\n",
    "if not DATA_RAW_DIR.exists():\n",
    "    DATA_RAW_DIR.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211522dd-c54e-4521-aa43-091ed7368a25",
   "metadata": {},
   "source": [
    "After prototyping the dataset loading process, let's create a function to load other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f62cf1f-e8ac-4b23-a838-0cec68d304ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename: Path):\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "\n",
    "    df[\"duration\"] = (df.lpep_dropoff_datetime - df.lpep_pickup_datetime).apply(\n",
    "        lambda dur: dur.total_seconds() / 60\n",
    "    )\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    df.PULocationID = df.PULocationID.astype(str)\n",
    "    df.DOLocationID = df.DOLocationID.astype(str)\n",
    "    df[\"PU_DO\"] = df.PULocationID + \"_\" + df.DOLocationID\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a417f7b8-6697-4b47-9196-8cc7ca3a7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_data(GREEN_TRIP_JAN)\n",
    "df_val = read_data(GREEN_TRIP_FEB)\n",
    "df_test = read_data(GREEN_TRIP_MAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1885070-5232-43fd-aef8-6b486c10e72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6076436-15de-4b8b-b645-47c58874bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c83c7fa-6240-4fc9-ba83-abb32515eb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2c730f-0882-4182-a0d7-8dfd78f8d3ef",
   "metadata": {},
   "source": [
    "## Start Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860c8ade-bcbf-4b04-bc33-f848e8178978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path(\"../outputs\")\n",
    "MODEL_DIR = OUTPUT_DIR / \"models\"\n",
    "if not MODEL_DIR.exists():\n",
    "    MODEL_DIR.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3428aa-d4b5-4ca9-9703-c765bebe5978",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"duration\"\n",
    "numerical_features = [\"trip_distance\"]\n",
    "categorical_features = [\"PU_DO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a422fe-e0d1-49a3-9385-554a662022c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = df_train[numerical_features + categorical_features]\n",
    "y_train = df_train[target]\n",
    "\n",
    "X_val = df_val[numerical_features + categorical_features]\n",
    "y_val = df_val[target]\n",
    "\n",
    "X_test = df_test[numerical_features + categorical_features]\n",
    "y_test = df_test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96075e4-338f-4eda-a586-ae1c4ae6adbc",
   "metadata": {},
   "source": [
    "### Without MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb173c48-27c5-4c95-a6a3-a0797cc4f4e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Pipeline(\n",
    "    [(\"featurizer\", ColumnTransformer([\n",
    "        (\"encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"), categorical_features)])),\n",
    "     (\"estimator\", LinearRegression())],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "train_pred = model.predict(X_train)\n",
    "train_mse = mean_squared_error(y_train, train_pred, squared=False)\n",
    "\n",
    "val_pred = model.predict(X_val)\n",
    "val_mse = mean_squared_error(y_val, val_pred, squared=False)\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, test_pred, squared=False)\n",
    "\n",
    "print(f\"Train MSE: {train_mse:.3f}.. Val MSE: {val_mse:.3f}.. Test MSE: {test_mse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f1f40-7da3-41a6-b47f-2e28bc8720f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Pipeline(\n",
    "    [(\"featurizer\", ColumnTransformer([\n",
    "        (\"encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"), categorical_features)])),\n",
    "     (\"estimator\", Lasso())],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "train_pred = model.predict(X_train)\n",
    "train_rmse = mean_squared_error(y_train, train_pred, squared=False)\n",
    "\n",
    "val_pred = model.predict(X_val)\n",
    "val_rmse = mean_squared_error(y_val, val_pred, squared=False)\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "test_rmse = mean_squared_error(y_test, test_pred, squared=False)\n",
    "\n",
    "print(f\"Train MSE: {train_rmse:.3f}.. Val MSE: {val_rmse:.3f}.. Test MSE: {test_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd40fb12-702c-4c65-9258-87b975f721e5",
   "metadata": {},
   "source": [
    "### With MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e11f5-d794-44e5-9afe-fd1f6858ffd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    mlflow.set_tag(\"developer\", \"dani\")\n",
    "\n",
    "    mlflow.log_param(\"train_data_path\", str(GREEN_TRIP_JAN))\n",
    "    mlflow.log_param(\"val_data_path\", str(GREEN_TRIP_FEB))\n",
    "    mlflow.log_param(\"test_data_path\", str(GREEN_TRIP_MAR))\n",
    "\n",
    "    alpha = 1.\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "\n",
    "    model = Pipeline(\n",
    "        [(\"featurizer\", ColumnTransformer([\n",
    "            (\"encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"), categorical_features)])),\n",
    "         (\"estimator\", Lasso(alpha=alpha))],\n",
    "        verbose=True\n",
    "    )\n",
    "    mlflow.set_tag(\"estimator\", model.named_steps[\"estimator\"].__class__.__name__)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "    train_rmse = mean_squared_error(y_train, train_pred, squared=False)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_rmse = mean_squared_error(y_val, val_pred, squared=False)\n",
    "    mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "\n",
    "    test_pred = model.predict(X_test)\n",
    "    test_rmse = mean_squared_error(y_test, test_pred, squared=False)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    joblib.dump(model, MODEL_DIR / \"model.joblib\")\n",
    "    mlflow.log_artifact(str(MODEL_DIR / \"model.joblib\"), artifact_path=\"artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13367d29-5ade-44e3-a7ff-0a067b673f85",
   "metadata": {},
   "source": [
    "## MLflow Tracking Server\n",
    "\n",
    "Since we now use a SQLite database to store the experiments metadata, we can't use the previous command `mlflow ui`. Instead, we should run a tracking server using command `mlflow server --backend-store-uri sqlite:///mlflow.db`.\n",
    "\n",
    "> The `--backend-store-uri URI` is used to tell the server to use the specified database to fetch all related metadata, such as experiments, runs, parameters, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c63b2-4e3d-4fbc-a5fc-7eee2ecf20f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_artifact_path = mlflow.artifacts.download_artifacts(\n",
    "    run.info.artifact_uri + \"/artifacts/model.joblib\",\n",
    "    dst_path=\"outputs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e60b81-4279-4e2d-9e6d-20f85ccb142d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_artifact = joblib.load(model_artifact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be5f3d-c721-4668-a94a-f6454300dc7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = model_artifact.predict(X_test)\n",
    "mean_squared_error(y_test, preds, squared=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
